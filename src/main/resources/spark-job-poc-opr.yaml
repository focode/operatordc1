apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: operatordc3
  namespace: dc-spark-poc
spec:
  type: Java
  mode: cluster
  image: "210761511742.dkr.ecr.eu-central-1.amazonaws.com/dc-spark-poc:operatordc11"
  imagePullPolicy: Always
  imagePullSecrets:
    - mdsp-secret-spark
  mainClass: "org.springframework.boot.loader.JarLauncher"
  mainApplicationFile: "local:///opt/spark/examples/jars/operatordc11.jar" # Ensure this is the correct path within your Docker image
  sparkVersion: "3.4.2"
  restartPolicy:
    type: Never
  driver:
    cores: 4
    coreLimit: "4000m"
    memory: "4096m"
    javaOptions: >-
      -Dlog4j.configuration=file:///log4j2.xml
      --add-opens=java.base/java.lang=ALL-UNNAMED
      --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
      --add-opens=java.base/java.nio=ALL-UNNAMED
      --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
      --add-opens=java.base/java.util=ALL-UNNAMED
      --add-opens=java.base/java.lang.invoke=ALL-UNNAMED
      --add-opens=java.base/jdk.internal.misc=ALL-UNNAMED
      -XX:+UseG1GC
      -XX:MaxGCPauseMillis=200
      -XX:G1HeapRegionSize=32M
      -XX:ReservedCodeCacheSize=100M
      -XX:MaxMetaspaceSize=256m
      -XX:CompressedClassSpaceSize=256m
      -Xms1024m
      -Dlog4j.debug
    labels:
      version: "3.4.2"
    serviceAccount: spark
  executor:
    cores: 4
    instances: 1
    memory: "6144m"
    javaOptions: >-
      -XX:ReservedCodeCacheSize=100M
      -XX:MaxMetaspaceSize=256m
      -XX:CompressedClassSpaceSize=256m
      --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
      -Dlog4j.debug
    labels:
      version: "3.4.2"
    serviceAccount: spark
  sparkConf:
    "spark.driver.userClassPathFirst": "true"
    "spark.executor.userClassPathFirst": "true"
    "spark.driver.memory": "4096m"
    "spark.executor.memory": "4096m"
    "spark.dynamicAllocation.enabled": "true"
    "spark.hadoop.fs.s3a.access.key": ""
    "spark.hadoop.fs.s3a.secret.key": ""
